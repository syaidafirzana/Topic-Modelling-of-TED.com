{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC MODELLING\n",
    "### Name: Nur Syaida Firzana\n",
    "### Id  : 66474666\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /homedirs/nsm91/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim import similarities\n",
    "\n",
    "import os.path\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "mallet_path = '/opt/mallet-2.0.8/bin/mallet' # this should be the correct path for the DIGI405 lab workrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### functions to load a corpus from a directory of text files, preprocess the corpus and create the bag of words document-term matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create document list:\n",
    "documents_list = []\n",
    "doc_register = {}\n",
    "\n",
    "def load_data_from_dir(path):\n",
    "    file_list = glob.glob(path + '/*.txt')\n",
    "    \n",
    "    for idx, filename in enumerate(file_list):\n",
    "        with open(filename, 'r', encoding='utf8') as f:\n",
    "            text = f.read()\n",
    "            documents_list.append(text)\n",
    "            doc_register[filename.split('/')[1]] = idx\n",
    "    print(\"Total Number of Documents:\",len(documents_list))\n",
    "    return documents_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(doc_set,extra_stopwords = {}):\n",
    "    # adapted from https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python\n",
    "    # replace all newlines or multiple sequences of spaces with a standard space\n",
    "    doc_set = [re.sub('\\s+', ' ', doc) for doc in doc_set]\n",
    "    # initialize regex tokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    # create English stop words list\n",
    "    en_stop = set(stopwords.words('english'))\n",
    "    # add any extra stopwords\n",
    "    if (len(extra_stopwords) > 0):\n",
    "        en_stop = en_stop.union(extra_stopwords)\n",
    "    \n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "    # loop through document list\n",
    "    for i in doc_set:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        # remove stop words from tokens\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        # add tokens to list\n",
    "        texts.append(stopped_tokens)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_corpus(doc_clean):\n",
    "    # adapted from https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python\n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    \n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "    return dictionary,doc_term_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and pre-process the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Documents: 3603\n"
     ]
    }
   ],
   "source": [
    "# adjust the path below to wherever you have the transcripts2018 folder\n",
    "document_list = load_data_from_dir(\"transcripts\")\n",
    "\n",
    "# I've added extra stopwords here in addition to NLTK's stopword list - you could look at adding others.\n",
    "doc_clean = preprocess_data(document_list,{'laughter','applause'})\n",
    "\n",
    "dictionary, doc_term_matrix = prepare_corpus(doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics=20 # adjust this to alter the number of topics\n",
    "words=20 #adjust this to alter the number of words output for the topic below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LDA model with 20 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_topics=20\n",
    "words=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamallet20 = LdaMallet(mallet_path, corpus=doc_term_matrix, num_topics=number_of_topics, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.014*\"human\" + 0.014*\"history\" + 0.012*\"century\" + 0.008*\"god\" + 0.006*\"culture\" + 0.005*\"age\" + 0.005*\"future\" + 0.005*\"story\" + 0.005*\"religion\" + 0.005*\"compassion\" + 0.005*\"past\" + 0.005*\"death\" + 0.004*\"modern\" + 0.004*\"sense\" + 0.004*\"ancient\" + 0.004*\"humanity\" + 0.004*\"religious\" + 0.004*\"man\" + 0.004*\"beings\" + 0.003*\"power\"'),\n",
       " (1,\n",
       "  '0.018*\"story\" + 0.016*\"book\" + 0.016*\"language\" + 0.016*\"words\" + 0.013*\"stories\" + 0.013*\"word\" + 0.013*\"read\" + 0.009*\"write\" + 0.008*\"books\" + 0.008*\"writing\" + 0.007*\"english\" + 0.007*\"wrote\" + 0.006*\"film\" + 0.006*\"talk\" + 0.006*\"voice\" + 0.006*\"love\" + 0.005*\"reading\" + 0.005*\"speak\" + 0.005*\"idea\" + 0.005*\"written\"'),\n",
       " (2,\n",
       "  '0.033*\"school\" + 0.030*\"children\" + 0.028*\"kids\" + 0.016*\"students\" + 0.014*\"child\" + 0.012*\"education\" + 0.011*\"learn\" + 0.011*\"learning\" + 0.010*\"young\" + 0.009*\"parents\" + 0.009*\"high\" + 0.007*\"schools\" + 0.007*\"teach\" + 0.007*\"college\" + 0.006*\"class\" + 0.006*\"teachers\" + 0.006*\"family\" + 0.006*\"learned\" + 0.006*\"teacher\" + 0.006*\"student\"'),\n",
       " (3,\n",
       "  '0.013*\"love\" + 0.011*\"home\" + 0.009*\"feel\" + 0.009*\"thought\" + 0.008*\"started\" + 0.008*\"family\" + 0.008*\"told\" + 0.007*\"knew\" + 0.007*\"felt\" + 0.007*\"wanted\" + 0.007*\"man\" + 0.007*\"night\" + 0.007*\"friends\" + 0.006*\"father\" + 0.006*\"mother\" + 0.005*\"remember\" + 0.005*\"asked\" + 0.005*\"moment\" + 0.005*\"days\" + 0.005*\"story\"'),\n",
       " (4,\n",
       "  '0.029*\"data\" + 0.019*\"information\" + 0.014*\"technology\" + 0.013*\"internet\" + 0.010*\"computer\" + 0.009*\"phone\" + 0.008*\"online\" + 0.008*\"video\" + 0.008*\"media\" + 0.007*\"digital\" + 0.006*\"network\" + 0.006*\"google\" + 0.006*\"open\" + 0.005*\"real\" + 0.005*\"web\" + 0.005*\"project\" + 0.005*\"facebook\" + 0.004*\"big\" + 0.004*\"started\" + 0.004*\"content\"'),\n",
       " (5,\n",
       "  '0.011*\"question\" + 0.009*\"social\" + 0.008*\"problem\" + 0.008*\"important\" + 0.006*\"understand\" + 0.006*\"wrong\" + 0.006*\"questions\" + 0.006*\"thinking\" + 0.006*\"answer\" + 0.006*\"change\" + 0.006*\"science\" + 0.006*\"human\" + 0.005*\"sense\" + 0.005*\"idea\" + 0.005*\"study\" + 0.005*\"person\" + 0.005*\"reason\" + 0.005*\"ways\" + 0.004*\"talk\" + 0.004*\"true\"'),\n",
       " (6,\n",
       "  '0.013*\"technology\" + 0.013*\"human\" + 0.009*\"machine\" + 0.009*\"dna\" + 0.009*\"system\" + 0.009*\"cell\" + 0.008*\"build\" + 0.007*\"robot\" + 0.007*\"computer\" + 0.006*\"machines\" + 0.006*\"design\" + 0.006*\"create\" + 0.006*\"cells\" + 0.006*\"process\" + 0.006*\"robots\" + 0.005*\"lab\" + 0.005*\"simple\" + 0.005*\"small\" + 0.005*\"future\" + 0.005*\"humans\"'),\n",
       " (7,\n",
       "  '0.026*\"music\" + 0.023*\"city\" + 0.016*\"design\" + 0.015*\"building\" + 0.013*\"art\" + 0.008*\"project\" + 0.008*\"space\" + 0.007*\"create\" + 0.007*\"place\" + 0.007*\"built\" + 0.007*\"idea\" + 0.007*\"cities\" + 0.006*\"house\" + 0.006*\"piece\" + 0.006*\"york\" + 0.005*\"architecture\" + 0.005*\"street\" + 0.005*\"buildings\" + 0.005*\"artist\" + 0.005*\"public\"'),\n",
       " (8,\n",
       "  '0.042*\"brain\" + 0.014*\"body\" + 0.012*\"sound\" + 0.008*\"sleep\" + 0.007*\"brains\" + 0.007*\"memory\" + 0.005*\"experience\" + 0.005*\"eyes\" + 0.005*\"mind\" + 0.005*\"human\" + 0.005*\"neurons\" + 0.005*\"sounds\" + 0.005*\"control\" + 0.005*\"face\" + 0.005*\"attention\" + 0.004*\"move\" + 0.004*\"visual\" + 0.004*\"activity\" + 0.004*\"consciousness\" + 0.004*\"physical\"'),\n",
       " (9,\n",
       "  '0.013*\"bit\" + 0.013*\"play\" + 0.012*\"sort\" + 0.012*\"yeah\" + 0.011*\"guy\" + 0.011*\"show\" + 0.010*\"talk\" + 0.010*\"stuff\" + 0.009*\"game\" + 0.009*\"pretty\" + 0.009*\"start\" + 0.008*\"thought\" + 0.008*\"thinking\" + 0.007*\"guys\" + 0.007*\"video\" + 0.007*\"real\" + 0.007*\"big\" + 0.006*\"idea\" + 0.005*\"hand\" + 0.005*\"started\"'),\n",
       " (10,\n",
       "  '0.019*\"countries\" + 0.016*\"africa\" + 0.016*\"country\" + 0.011*\"global\" + 0.011*\"china\" + 0.010*\"india\" + 0.008*\"percent\" + 0.007*\"change\" + 0.006*\"population\" + 0.006*\"states\" + 0.006*\"development\" + 0.006*\"million\" + 0.006*\"united\" + 0.006*\"poverty\" + 0.005*\"local\" + 0.005*\"growth\" + 0.005*\"poor\" + 0.005*\"europe\" + 0.005*\"chinese\" + 0.005*\"african\"'),\n",
       " (11,\n",
       "  '0.020*\"000\" + 0.020*\"percent\" + 0.018*\"number\" + 0.015*\"10\" + 0.013*\"car\" + 0.012*\"million\" + 0.011*\"1\" + 0.010*\"half\" + 0.009*\"times\" + 0.009*\"2\" + 0.009*\"100\" + 0.009*\"ca\" + 0.009*\"30\" + 0.008*\"20\" + 0.008*\"numbers\" + 0.008*\"ago\" + 0.007*\"problem\" + 0.006*\"50\" + 0.006*\"cars\" + 0.006*\"3\"'),\n",
       " (12,\n",
       "  '0.022*\"light\" + 0.020*\"space\" + 0.016*\"earth\" + 0.014*\"universe\" + 0.008*\"planet\" + 0.008*\"science\" + 0.007*\"sun\" + 0.006*\"matter\" + 0.006*\"stars\" + 0.006*\"black\" + 0.006*\"dark\" + 0.006*\"mars\" + 0.006*\"theory\" + 0.006*\"physics\" + 0.005*\"moon\" + 0.005*\"big\" + 0.005*\"energy\" + 0.005*\"sky\" + 0.005*\"planets\" + 0.004*\"object\"'),\n",
       " (13,\n",
       "  '0.021*\"money\" + 0.016*\"business\" + 0.014*\"dollars\" + 0.012*\"company\" + 0.010*\"companies\" + 0.009*\"market\" + 0.008*\"percent\" + 0.007*\"buy\" + 0.007*\"pay\" + 0.006*\"jobs\" + 0.006*\"industry\" + 0.005*\"innovation\" + 0.005*\"product\" + 0.005*\"economy\" + 0.005*\"cost\" + 0.005*\"financial\" + 0.005*\"economic\" + 0.004*\"working\" + 0.004*\"create\" + 0.004*\"making\"'),\n",
       " (14,\n",
       "  '0.026*\"water\" + 0.022*\"energy\" + 0.012*\"climate\" + 0.010*\"change\" + 0.010*\"carbon\" + 0.009*\"air\" + 0.009*\"oil\" + 0.009*\"power\" + 0.008*\"planet\" + 0.006*\"waste\" + 0.006*\"nuclear\" + 0.006*\"solar\" + 0.006*\"earth\" + 0.006*\"global\" + 0.005*\"gas\" + 0.005*\"problem\" + 0.005*\"future\" + 0.005*\"electricity\" + 0.005*\"system\" + 0.005*\"natural\"'),\n",
       " (15,\n",
       "  '0.046*\"women\" + 0.024*\"men\" + 0.017*\"woman\" + 0.015*\"black\" + 0.011*\"girls\" + 0.010*\"white\" + 0.010*\"sex\" + 0.009*\"talk\" + 0.008*\"young\" + 0.007*\"girl\" + 0.007*\"man\" + 0.006*\"gender\" + 0.006*\"female\" + 0.005*\"sexual\" + 0.005*\"community\" + 0.005*\"love\" + 0.005*\"male\" + 0.005*\"feel\" + 0.004*\"violence\" + 0.004*\"race\"'),\n",
       " (16,\n",
       "  '0.019*\"health\" + 0.016*\"cancer\" + 0.014*\"disease\" + 0.011*\"care\" + 0.011*\"patients\" + 0.011*\"medical\" + 0.010*\"blood\" + 0.010*\"heart\" + 0.010*\"cells\" + 0.008*\"patient\" + 0.008*\"body\" + 0.007*\"drugs\" + 0.007*\"drug\" + 0.007*\"treatment\" + 0.006*\"doctors\" + 0.006*\"medicine\" + 0.006*\"doctor\" + 0.006*\"hospital\" + 0.005*\"diseases\" + 0.005*\"research\"'),\n",
       " (17,\n",
       "  '0.012*\"water\" + 0.012*\"ocean\" + 0.009*\"sea\" + 0.008*\"feet\" + 0.008*\"ice\" + 0.006*\"place\" + 0.006*\"deep\" + 0.005*\"north\" + 0.005*\"places\" + 0.005*\"surface\" + 0.005*\"earth\" + 0.005*\"000\" + 0.005*\"fly\" + 0.004*\"high\" + 0.004*\"river\" + 0.004*\"air\" + 0.004*\"mountain\" + 0.004*\"ground\" + 0.004*\"miles\" + 0.004*\"foot\"'),\n",
       " (18,\n",
       "  '0.021*\"food\" + 0.017*\"species\" + 0.015*\"animals\" + 0.009*\"eat\" + 0.007*\"animal\" + 0.007*\"human\" + 0.007*\"fish\" + 0.006*\"humans\" + 0.005*\"found\" + 0.005*\"plants\" + 0.005*\"plant\" + 0.005*\"trees\" + 0.005*\"living\" + 0.005*\"bacteria\" + 0.005*\"tree\" + 0.004*\"birds\" + 0.004*\"nature\" + 0.004*\"feed\" + 0.004*\"eating\" + 0.004*\"live\"'),\n",
       " (19,\n",
       "  '0.013*\"war\" + 0.009*\"political\" + 0.009*\"government\" + 0.008*\"power\" + 0.008*\"country\" + 0.008*\"states\" + 0.006*\"police\" + 0.006*\"law\" + 0.006*\"united\" + 0.005*\"rights\" + 0.005*\"public\" + 0.005*\"state\" + 0.005*\"security\" + 0.005*\"democracy\" + 0.005*\"american\" + 0.005*\"military\" + 0.005*\"politics\" + 0.004*\"president\" + 0.004*\"justice\" + 0.004*\"america\"')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output the topics\n",
    "ldamallet20.show_topics(num_topics=number_of_topics,num_words=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert to Gensim model format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gensimmodel20 = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get a coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544693353469589\n"
     ]
    }
   ],
   "source": [
    "coherencemodel = CoherenceModel(model=gensimmodel20, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "print (coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5383706283393228\n"
     ]
    }
   ],
   "source": [
    "ldamallet30 = LdaMallet(mallet_path, corpus=doc_term_matrix, num_topics=30, id2word=dictionary)\n",
    "gensimmodel30 = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet30)\n",
    "coherencemodel = CoherenceModel(model=gensimmodel30, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "print (coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test a range of topic sizes and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply values for k and the interval, eg 20, 60, 10 will train models for 20, 30, 40, 50, and 60 topics\n",
    "min_k = 5\n",
    "max_k = 40\n",
    "intervals = 5\n",
    "\n",
    "coherences = {}\n",
    "\n",
    "for i in range(min_k, max_k, intervals):\n",
    "    ldamalletmodel = LdaMallet(mallet_path, corpus=doc_term_matrix, num_topics=i, id2word=dictionary)\n",
    "    gensimmodel = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamalletmodel)\n",
    "    coherences[i] = CoherenceModel(model=gensimmodel, texts=doc_clean, dictionary=dictionary, coherence='c_v').get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convert the coherence scores to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the coherence scores to a pandas dataframe\n",
    "df = pd.DataFrame.from_dict(coherences, orient='index', columns=['Coherence'])\n",
    "df['Topics'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f4a35c48150>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.plot(kind='line', x='Topics', y='Coherence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 5 has coherence value of 0.41437\n",
      "Num Topics = 10 has coherence value of 0.46368\n",
      "Num Topics = 15 has coherence value of 0.51783\n",
      "Num Topics = 20 has coherence value of 0.53277\n",
      "Num Topics = 25 has coherence value of 0.55145\n",
      "Num Topics = 30 has coherence value of 0.54598\n",
      "Num Topics = 35 has coherence value of 0.559\n"
     ]
    }
   ],
   "source": [
    "x = range(min_k, max_k, intervals)\n",
    "for m, i in zip(x, coherences):\n",
    "    print(\"Num Topics =\",m, \"has coherence value of\", round(coherences[i], 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preview a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_register['2012-09-14-timothy_bartik_the_economic_case_for_preschool.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You probably don't know me, but I am one of those .01 percenters that you hear about and read about, and I am by any reasonable definition a plutocrat. And tonight, what I would like to do is speak directly to other plutocrats, to my people, because it feels like it's time for us all to have a chat. Like most plutocrats, I too am a proud and unapologetic capitalist. I have founded, cofounded or funded over 30 companies across a range of industries. I was the first non-family investor in Amazon.com. I cofounded a company called aQuantive that we sold to Microsoft for 6.4 billion dollars. My friends and I, we own a bank. I tell you this — (Laughter) — unbelievable, right? I tell you this to show that my life is like most plutocrats. I have a broad perspective on capitalism and business, and I have been rewarded obscenely for that with a life that most of you all can't even imagine: multiple homes, a yacht, my own plane, etc., etc., etc. But let's be honest: I am not the smartest person you've ever met. I am certainly not the hardest working. I was a mediocre student. I'm not technical at all. I can't write a word of code. Truly, my success is the consequence of spectacular luck, of birth, of circumstance and of timing. But I am actually pretty good at a couple of things. One, I have an unusually high tolerance for risk, and the other is I have a good sense, a good intuition about what will happen in the future, and I think that that intuition about the future is the essence of good entrepreneurship. So what do I see in our future today, you ask? I see pitchforks, as in angry mobs with pitchforks, because while people like us plutocrats are living beyond the dreams of avarice, the other 99 percent of our fellow citizens are falling farther and farther behind. In 1980, the top one percent of Americans shared about eight percent of national [income], while the bottom 50 percent of Americans shared 18 percent. Thirty years later, today, the top one percent shares over 20 percent of national [income], while the bottom 50 percent of Americans share 12 or 13. If the trend continues, the top one percent will share over 30 percent of national [income] in another 30 years, while the bottom 50 percent of Americans will share just six. You see, the problem isn't that we have some inequality. Some inequality is necessary for a high-functioning capitalist democracy. The problem is that inequality is at historic highs today and it's getting worse every day. And if wealth, power, and income continue to concentrate at the very tippy top, our society will change from a capitalist democracy to a neo-feudalist rentier society like 18th-century France. That was France before the revolution and the mobs with the pitchforks. So I have a message for my fellow plutocrats and zillionaires and for anyone who lives in a gated bubble world: Wake up. Wake up. It cannot last. Because if we do not do something to fix the glaring economic inequities in our society, the pitchforks will come for us, for no free and open society can long sustain this kind of rising economic inequality. It has never happened. There are no examples. You show me a highly unequal society, and I will show you a police state or an uprising. The pitchforks will come for us if we do not address this. It's not a matter of if, it's when. And it will be terrible when they come for everyone, but particularly for people like us plutocrats. I know I must sound like some liberal do-gooder. I'm not. I'm not making a moral argument that economic inequality is wrong. What I am arguing is that rising economic inequality is stupid and ultimately self-defeating. Rising inequality doesn't just increase our risks from pitchforks, but it's also terrible for business too. So the model for us rich guys should be Henry Ford. When Ford famously introduced the $5 day, which was twice the prevailing wage at the time, he didn't just increase the productivity of his factories, he converted exploited autoworkers who were poor into a thriving middle class who could now afford to buy the products that they made. Ford intuited what we now know is true, that an economy is best understood as an ecosystem and characterized by the same kinds of feedback loops you find in a natural ecosystem, a feedback loop between customers and businesses. Raising wages increases demand, which increases hiring, which in turn increases wages and demand and profits, and that virtuous cycle of increasing prosperity is precisely what is missing from today's economic recovery. And this is why we need to put behind us the trickle-down policies that so dominate both political parties and embrace something I call middle-out economics. Middle-out economics rejects the neoclassical economic idea that economies are efficient, linear, mechanistic, that they tend towards equilibrium and fairness, and instead embraces the 21st-century idea that economies are complex, adaptive, ecosystemic, that they tend away from equilibrium and toward inequality, that they're not efficient at all but are effective if well managed. This 21st-century perspective allows you to clearly see that capitalism does not work by [efficiently] allocating existing resources. It works by [efficiently] creating new solutions to human problems. The genius of capitalism is that it is an evolutionary solution-finding system. It rewards people for solving other people's problems. The difference between a poor society and a rich society, obviously, is the degree to which that society has generated solutions in the form of products for its citizens. The sum of the solutions that we have in our society really is our prosperity, and this explains why companies like Google and Amazon and Microsoft and Apple and the entrepreneurs who created those companies have contributed so much to our nation's prosperity. This 21st-century perspective also makes clear that what we think of as economic growth is best understood as the rate at which we solve problems. But that rate is totally dependent upon how many problem solvers — diverse, able problem solvers — we have, and thus how many of our fellow citizens actively participate, both as entrepreneurs who can offer solutions, and as customers who consume them. But this maximizing participation thing doesn't happen by accident. It doesn't happen by itself. It requires effort and investment, which is why all highly prosperous capitalist democracies are characterized by massive investments in the middle class and the infrastructure that they depend on. We plutocrats need to get this trickle-down economics thing behind us, this idea that the better we do, the better everyone else will do. It's not true. How could it be? I earn 1,000 times the median wage, but I do not buy 1,000 times as much stuff, do I? I actually bought two pairs of these pants, what my partner Mike calls my manager pants. I could have bought 2,000 pairs, but what would I do with them? (Laughter) How many haircuts can I get? How often can I go out to dinner? No matter how wealthy a few plutocrats get, we can never drive a great national economy. Only a thriving middle class can do that. There's nothing to be done, my plutocrat friends might say. Henry Ford was in a different time. Maybe we can't do some things. Maybe we can do some things. June 19, 2013, Bloomberg published an article I wrote called \"The Capitalist’s Case for a $15 Minimum Wage.\" The good people at Forbes magazine, among my biggest admirers, called it \"Nick Hanauer's near-insane proposal.\" And yet, just 350 days after that article was published, Seattle's Mayor Ed Murray signed into law an ordinance raising the minimum wage in Seattle to 15 dollars an hour, more than double what the prevailing federal $7.25 rate is. How did this happen, reasonable people might ask. It happened because a group of us reminded the middle class that they are the source of growth and prosperity in capitalist economies. We reminded them that when workers have more money, businesses have more customers, and need more employees. We reminded them that when businesses pay workers a living wage, taxpayers are relieved of the burden of funding the poverty programs like food stamps and medical assistance and rent assistance that those workers need. We reminded them that low-wage workers make terrible taxpayers, and that when you raise the minimum wage for all businesses, all businesses benefit yet all can compete. Now the orthodox reaction, of course, is raising the minimum wage costs jobs. Right? Your politician's always echoing that trickle-down idea by saying things like, \"Well, if you raise the price of employment, guess what happens? You get less of it.\" Are you sure? Because there's some contravening evidence. Since 1980, the wages of CEOs in our country have gone from about 30 times the median wage to 500 times. That's raising the price of employment. And yet, to my knowledge, I have never seen a company outsource its CEO's job, automate their job, export the job to China. In fact, we appear to be employing more CEOs and senior managers than ever before. So too for technology workers and financial services workers, who earn multiples of the median wage and yet we employ more and more of them, so clearly you can raise the price of employment and get more of it. I know that most people think that the $15 minimum wage is this insane, risky economic experiment. We disagree. We believe that the $15 minimum wage in Seattle is actually the continuation of a logical economic policy. It is allowing our city to kick your city's ass. Because, you see, Washington state already has the highest minimum wage of any state in the nation. We pay all workers $9.32, which is almost 30 percent more than the federal minimum of 7.25, but crucially, 427 percent more than the federal tipped minimum of 2.13. If trickle-down thinkers were right, then Washington state should have massive unemployment. Seattle should be sliding into the ocean. And yet, Seattle is the fastest-growing big city in the country. Washington state is generating small business jobs at a higher rate than any other major state in the nation. The restaurant business in Seattle? Booming. Why? Because the fundamental law of capitalism is, when workers have more money, businesses have more customers and need more workers. When restaurants pay restaurant workers enough so that even they can afford to eat in restaurants, that's not bad for the restaurant business. That's good for it, despite what some restaurateurs may tell you. Is it more complicated than I'm making out? Of course it is. There are a lot of dynamics at play. But can we please stop insisting that if low-wage workers earn a little bit more, unemployment will skyrocket and the economy will collapse? There is no evidence for it. The most insidious thing about trickle-down economics is not the claim that if the rich get richer, everyone is better off. It is the claim made by those who oppose any increase in the minimum wage that if the poor get richer, that will be bad for the economy. This is nonsense. So can we please dispense with this rhetoric that says that rich guys like me and my plutocrat friends made our country? We plutocrats know, even if we don't like to admit it in public, that if we had been born somewhere else, not here in the United States, we might very well be just some dude standing barefoot by the side of a dirt road selling fruit. It's not that they don't have good entrepreneurs in other places, even very, very poor places. It's just that that's all that those entrepreneurs' customers can afford. So here's an idea for a new kind of economics, a new kind of politics that I call new capitalism. Let's acknowledge that capitalism beats the alternatives, but also that the more people we include, both as entrepreneurs and as customers, the better it works. Let's by all means shrink the size of government, but not by slashing the poverty programs, but by ensuring that workers are paid enough so that they actually don't need those programs. Let's invest enough in the middle class to make our economy fairer and more inclusive, and by fairer, more truly competitive, and by more truly competitive, more able to generate the solutions to human problems that are the true drivers of growth and prosperity. Capitalism is the greatest social technology ever invented for creating prosperity in human societies, if it is well managed, but capitalism, because of the fundamental multiplicative dynamics of complex systems, tends towards, inexorably, inequality, concentration and collapse. The work of democracies is to maximize the inclusion of the many in order to create prosperity, not to enable the few to accumulate money. Government does create prosperity and growth, by creating the conditions that allow both entrepreneurs and their customers to thrive. Balancing the power of capitalists like me and workers isn't bad for capitalism. It's essential to it. Programs like a reasonable minimum wage, affordable healthcare, paid sick leave, and the progressive taxation necessary to pay for the important infrastructure necessary for the middle class like education, R and D, these are indispensable tools shrewd capitalists should embrace to drive growth, because no one benefits from it like us. Many economists would have you believe that their field is an objective science. I disagree, and I think that it is equally a tool that humans use to enforce and encode our social and moral preferences and prejudices about status and power, which is why plutocrats like me have always needed to find persuasive stories to tell everyone else about why our relative positions are morally righteous and good for everyone: like, we are indispensable, the job creators, and you are not; like, tax cuts for us create growth, but investments in you will balloon our debt and bankrupt our great country; that we matter; that you don't. For thousands of years, these stories were called divine right. Today, we have trickle-down economics. How obviously, transparently self-serving all of this is. We plutocrats need to see that the United States of America made us, not the other way around; that a thriving middle class is the source of prosperity in capitalist economies, not a consequence of it. And we should never forget that even the best of us in the worst of circumstances are barefoot by the side of a dirt road selling fruit. Fellow plutocrats, I think it may be time for us to recommit to our country, to commit to a new kind of capitalism which is both more inclusive and more effective, a capitalism that will ensure that America's economy remains the most dynamic and prosperous in the world. Let's secure the future for ourselves, our children and their children. Or alternatively, we could do nothing, hide in our gated communities and private schools, enjoy our planes and yachts — they're fun — and wait for the pitchforks. Thank you. (Applause)\n"
     ]
    }
   ],
   "source": [
    "doc_id = 1117 # index of document to explore\n",
    "print(re.sub('\\s+', ' ', document_list[doc_id])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output the distribution of topics for the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42 13 ['money', 'business', 'dollars', 'company', 'companies', 'market', 'percent', 'buy', 'pay', 'jobs']\n",
      "0.17 2 ['school', 'children', 'kids', 'students', 'child', 'education', 'learn', 'learning', 'young', 'parents']\n",
      "0.15 5 ['question', 'social', 'problem', 'important', 'understand', 'wrong', 'questions', 'thinking', 'answer', 'change']\n",
      "0.11 10 ['countries', 'africa', 'country', 'global', 'china', 'india', 'percent', 'change', 'population', 'states']\n",
      "0.04 11 ['000', 'percent', 'number', '10', 'car', 'million', '1', 'half', 'times', '2']\n",
      "0.02 19 ['war', 'political', 'government', 'power', 'country', 'states', 'police', 'law', 'united', 'rights']\n"
     ]
    }
   ],
   "source": [
    "document_topics = gensimmodel20.get_document_topics(doc_term_matrix[doc_id]) # substitute other models here\n",
    "document_topics = sorted(document_topics, key=lambda x: x[1], reverse=True) # sorts document topics\n",
    "\n",
    "for topic, prop in document_topics:\n",
    "    topic_words = [word[0] for word in gensimmodel20.show_topic(topic, 10)]\n",
    "    print (\"%.2f\" % prop, topic, topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find similar documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Index:  2046\n",
      "Filename: ./transcripts/2013-06-26-mariana_mazzucato_government_investor_risk_taker_innovator.txt\n",
      "Similarity Score 0.3059151\n",
      "Have you ever asked yourselves why it is that companies, the really cool companies, the innovative ones, the creative, new economy-type companies — Apple, Google, Facebook — are coming out of one particular country, the United States of America? Usually when I say this, someone says, \"Spotify! That's Europe.\" But, yeah. It has not had the impact that these other companies have had. Now what I do is I'm an economist, and I actually study the relationship between innovation and economic growth at ...\n",
      "Document Index:  2855\n",
      "Filename: ./transcripts/2019-04-15-claudia_miner_a_new_way_to_get_every_child_ready_for_kindergarten.txt\n",
      "Similarity Score 0.29231533\n",
      "I'm an historian. And what I love about being an historian is it gives you perspective. Today, I'd like to bring that perspective to education in the United States. About the only thing people can agree on is that the most strategic time for a child to start learning is early. Over 50 years ago, there was a watershed moment in early education in the US called \"Head Start.\" Now, historians love watersheds because it makes it so easy to talk about what came before and what's happened since. Befor ...\n",
      "Document Index:  1117\n",
      "Filename: ./transcripts/2014-08-06-nick_hanauer_beware_fellow_plutocrats_the_pitchforks_are_coming.txt\n",
      "Similarity Score 0.26828903\n",
      "You probably don't know me, but I am one of those .01 percenters that you hear about and read about, and I am by any reasonable definition a plutocrat. And tonight, what I would like to do is speak directly to other plutocrats, to my people, because it feels like it's time for us all to have a chat. Like most plutocrats, I too am a proud and unapologetic capitalist. I have founded, cofounded or funded over 30 companies across a range of industries. I was the first non-family investor in Amazon.c ...\n"
     ]
    }
   ],
   "source": [
    "model_doc_topics = gensimmodel20.get_document_topics(doc_term_matrix) # substitute other models here\n",
    "lda_index = similarities.MatrixSimilarity(model_doc_topics.corpus)\n",
    "    \n",
    "# query for our doc_id from above\n",
    "similarity_index = lda_index[doc_term_matrix[doc_id]]\n",
    "# Sort the similarity index\n",
    "similarity_index = sorted(enumerate(similarity_index), key=lambda item: -item[1])\n",
    "file_list = glob.glob('./transcripts/*.txt')\n",
    "for i in range(1,4): \n",
    "    document_id, similarity_score = similarity_index[i]\n",
    "    print('Document Index: ',document_id)\n",
    "    print('Filename:', file_list[document_id])\n",
    "    print('Similarity Score',similarity_score)\n",
    "    print(re.sub('\\s+', ' ', document_list[document_id][:500]), '...') # preview first 500 characters\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
